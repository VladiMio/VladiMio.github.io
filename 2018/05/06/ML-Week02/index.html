<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="VladiMio,jasper1992ws@hotmail.com"><title>机器学习笔记 02 · 简单易懂的现代魔法</title><!-- hexo-inject:begin --><!-- hexo-inject:end --><meta name="description" content="考虑下面一种情况：我们打算用机器学习预测某地的房价，为此我们收集了一些样本作为参考

为了方便表示，我们用如下符号定义该样本
\[
\begin{align*}
x_j^{(i)} &amp;amp;= \text{value of feature } j \text{ in the }i^{th"><meta name="keywords"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">简单易懂的现代魔法</a></h3><div class="description"><p>万国の労働者よ、団結せよ!</p></div></div></div><ul class="social-links"><li><a href="http://weibo.com/u/1596079301"><i class="fa fa-weibo"></i></a></li><li><a href="http://github.com/VladiMio"><i class="fa fa-github"></i></a></li></ul></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>机器学习笔记 02</a></h3></div><div class="post-content"><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
<!-- hexo-inject:begin --><!-- hexo-inject:end --></script>
<p>考虑下面一种情况：我们打算用机器学习预测某地的房价，为此我们收集了一些样本作为参考</p>
<p><img src="http://ogptt11t8.bkt.clouddn.com/MLWeek02-001.png"></p>
<p>为了方便表示，我们用如下符号定义该样本</p>
<p><span class="math display">\[
\begin{align*}
x_j^{(i)} &amp;= \text{value of feature } j \text{ in the }i^{th}\text{ training example} \newline
x^{(i)}&amp; = \text{the input (features) of the }i^{th}\text{ training example} \newline
m &amp;= \text{the number of training examples} \newline
n &amp;= \text{the number of features}
\end{align*}
\]</span></p>
<p>对应的假设函数可以写作： <span class="math display">\[
\begin{align*}
h_\theta(x) &amp;= \theta_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_3 + \cdots + \theta_nx_n \newline
&amp;=\begin{bmatrix}\theta_0 \hspace{2em} \theta_1 \hspace{2em} ... \hspace{2em} \theta_n\end{bmatrix}\begin{bmatrix}x_0 \newline x_1 \newline \vdots \newline x_n\end{bmatrix}= \theta^T x
\end{align*}
\]</span> 对假设函数<span class="math inline">\(h_\theta(x)=\theta^T x\)</span>使用梯度下降方法： <span class="math display">\[
\begin{align*}&amp; \text{repeat until convergence:} \; \lbrace \newline \; &amp; \theta_j := \theta_j - \alpha \frac{1}{m} \sum\limits_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} \; &amp; \text{for j := 0...n}\newline \rbrace\end{align*}
\]</span> 即可得到最优的假设函数<span class="math inline">\(h_\theta(x)\)</span>. 这就是 <strong>Multivariate Linear Regression (多元线性回归)</strong> 的基本方法。</p>
<h3 id="feature-scaling-特征缩放">Feature Scaling (特征缩放)</h3>
<p>当样本中某些特征值 (<span class="math inline">\(x\)</span>) 的范围过大或过小时，针对其的梯度下降算法可能会收敛的非常慢，因此我们引入 <strong>Feature Scaling (特征缩放)</strong> 来加快这一过程： <span class="math display">\[
x_i := \frac{x_i-\mu_i}{s_i}
\]</span> 其中，<span class="math inline">\(\mu_i\)</span>是所有<span class="math inline">\(x_i\)</span>的平均值，<span class="math inline">\(s_i\)</span>是其范围 <span class="math inline">\(max(x_i) - min(x_i)\)</span> ，或者<span class="math inline">\(x_i\)</span>的均方差。</p>
<h3 id="learning-rate-学习速率">Learning Rate (学习速率)</h3>
<p>即梯度下降方程 <span class="math display">\[
\theta_j := \theta_j - \alpha \frac{1}{m} \sum\limits_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})
\]</span> 中的迭代步长<span class="math inline">\(\alpha\)</span>。在实际问题中，<span class="math inline">\(\alpha\)</span>一般都应取得一个适当的值：太小的<span class="math inline">\(\alpha\)</span>会使梯度下降收敛地太慢，而过大的<span class="math inline">\(\alpha\)</span>也有可能使方程在局部极小值附近震荡，无法收敛 (如下图示) <img src="http://ogptt11t8.bkt.clouddn.com/MLWeek02-002.png" alt="α过大导致代价方程无法收敛"></p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2018-05-06</span><i class="fa fa-comment-o"></i><a href="/2018/05/06/ML-Week02/#comments">评论</a><i class="fa fa-tag"></i><a href="/categories/Machine-learning/" title="Machine-learning" class="tag">Machine-learning </a><a href="/tags/学习笔记/" title="学习笔记" class="tag">学习笔记 </a></div></div></div></div><div class="share"><div class="evernote"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"><a href="http://twitter.com/home?status=,http://VladiMio.github.io/2018/05/06/ML-Week02/,简单易懂的现代魔法,机器学习笔记 02,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="next pagbuttons"><a role="navigation" href="/2018/05/03/ML-Week01/" title="机器学习笔记 01" class="btn">下一篇</a></li></ul></div><a id="comments"></a><div id="disqus_thread"></div><script>var disqus_shortname = 'vladimio-me';
var disqus_identifier = '2018/05/06/ML-Week02/';
var disqus_title = '机器学习笔记 02';
var disqus_url = 'http://VladiMio.github.io/2018/05/06/ML-Week02/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//vladimio-me.disqus.com/count.js" async></script></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>